{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nWorking with sensor locations\n=============================\n\nThis tutorial describes how to plot sensor locations, and how the physical\nlocation of sensors is handled in MNE-Python.\n   :depth: 2\n\nAs usual we'll start by importing the modules we need and loading some\n`example data <sample-dataset>`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D  # noqa\nimport mne\n\nsample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n                                    'sample_audvis_raw.fif')\nraw = mne.io.read_raw_fif(sample_data_raw_file, preload=True, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "About montages and layouts\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nMNE-Python comes pre-loaded with information about the sensor positions of\nmany MEG and EEG systems. This information is stored in *layout files* and\n*montages*. :class:`Layouts <mne.channels.Layout>` give sensor positions in 2\ndimensions (defined by ``x``, ``y``, ``width``, and ``height`` values for\neach sensor), and are primarily used for illustrative purposes (i.e., making\ndiagrams of approximate sensor positions in top-down diagrams of the head).\nIn contrast, :class:`montages <mne.channels.Montage>` give sensor positions\nin 3D (``x``, ``y``, ``z``, in meters). Many layout and montage files are\nincluded during MNE-Python installation, and are stored in your\n``mne-python`` directory, in the :file:`mne/channels/data/layouts` and\n:file:`mne/channels/data/montages` folders, respectively:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = os.path.join(os.path.dirname(mne.__file__), 'channels', 'data')\nfor subfolder in ['layouts', 'montages']:\n    print('\\nBUILT-IN {} FILES'.format(subfolder[:-1].upper()))\n    print('======================')\n    print(sorted(os.listdir(os.path.join(data_dir, subfolder))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. sidebar:: Computing sensor locations\n\n    If you are interested in how standard (\"idealized\") EEG sensor positions\n    are computed on a spherical head model, the `eeg_positions`_ repository\n    provides code and documentation to this end.\n\nAs you may be able to tell from the filenames shown above, the included\nmontage files are all for EEG systems. These are *idealized* sensor positions\nbased on a spherical head model. Montage files for MEG systems are not\nprovided because the 3D coordinates of MEG sensors are included in the raw\nrecordings from MEG systems, and are automatically stored in the ``info``\nattribute of the :class:`~mne.io.Raw` file upon loading. In contrast, layout\nfiles *are* included for MEG systems (to facilitate easy plotting of MEG\nsensor location diagrams).\n\nYou may also have noticed that the file formats and filename extensions of\nlayout and montage files vary considerably. This reflects different\nmanufacturers' conventions; to simplify this, the montage and layout loading\nfunctions in MNE-Python take the filename *without its extension* so you\ndon't have to keep track of which file format is used by which manufacturer.\nExamples of this can be seen in the following sections.\n\nIf you have digitized the locations of EEG sensors on the scalp during your\nrecording session (e.g., with a Polhemous Fastrak digitizer), these can be\nloaded in MNE-Python as :class:`~mne.channels.DigMontage` objects; see\n`reading-dig-montages` (below).\n\n\nWorking with layout files\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo load a layout file, use the :func:`mne.channels.read_layout`\nfunction, and provide the filename *without* its file extension. You can then\nvisualize the layout using its :meth:`~mne.channels.Layout.plot` method, or\n(equivalently) by passing it to :func:`mne.viz.plot_layout`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_layout = mne.channels.read_layout('biosemi')\nbiosemi_layout.plot()  # same result as: mne.viz.plot_layout(biosemi_layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the ``picks`` argument for selecting channels from\n:class:`~mne.io.Raw` objects, the :meth:`~mne.channels.Layout.plot` method of\n:class:`~mne.channels.Layout` objects also has a ``picks`` argument. However,\nbecause layouts only contain information about sensor name and location (not\nsensor type), the :meth:`~mne.channels.Layout.plot` method only allows\npicking channels by index (not by name or by type). Here we find the indices\nwe want using :func:`numpy.where`; selection by name or type is possible via\n:func:`mne.pick_channels` or :func:`mne.pick_types`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "midline = np.where([name.endswith('z') for name in biosemi_layout.names])[0]\nbiosemi_layout.plot(picks=midline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're working with a :class:`~mne.io.Raw` object that already has sensor\npositions incorporated, you can create a :class:`~mne.channels.Layout` object\nwith either the :func:`mne.channels.make_eeg_layout` function or\n(equivalently) the :func:`mne.channels.find_layout` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_from_raw = mne.channels.make_eeg_layout(raw.info)\n# same result as: mne.channels.find_layout(raw.info, ch_type='eeg')\nlayout_from_raw.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There is no corresponding ``make_meg_layout`` function because sensor\n    locations are fixed in a MEG system (unlike in EEG, where the sensor caps\n    deform to fit each subject's head). Thus MEG layouts are consistent for a\n    given system and you can simply load them with\n    :func:`mne.channels.read_layout`, or use :func:`mne.channels.find_layout`\n    with the ``ch_type`` parameter, as shown above for EEG.</p></div>\n\nAll :class:`~mne.channels.Layout` objects have a\n:meth:`~mne.channels.Layout.save` method that allows writing layouts to disk,\nin either :file:`.lout` or :file:`.lay` format (which format gets written is\ninferred from the file extension you pass to the method's ``fname``\nparameter). The choice between :file:`.lout` and :file:`.lay` format only\nmatters if you need to load the layout file in some other software\n(MNE-Python can read either format equally well).\n\n\nWorking with montage files\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBuilt-in montages are loaded and plotted in a very similar way to layouts.\nHowever, the :meth:`~mne.channels.Montage.plot` method of\n:class:`~mne.channels.Montage` objects has some additional parameters, such\nas whether to display channel names or just points (the ``show_names``\nparameter) and whether to display sensor positions in 3D or as a 2D topomap\n(the ``kind`` parameter):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ten_twenty_montage = mne.channels.read_montage('standard_1020')\nten_twenty_montage.plot(show_names=False)\nfig = ten_twenty_montage.plot(kind='3d')\nfig.gca().view_init(azim=70, elev=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar functionality is also available with the\n:meth:`~mne.io.Raw.plot_sensors` method of :class:`~mne.io.Raw` objects,\nagain with the option to plot in either 2D or 3D.\n:meth:`~mne.io.Raw.plot_sensors` also allows channel selection by type, can\ncolor-code channels in various ways (by default, channels listed in\n``raw.info['bads']`` will be plotted in red), and allows drawing into an\nexisting matplotlib ``axes`` object (so the channel positions can easily be\nmade as a subplot in a multi-panel figure):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax2d = fig.add_subplot(121)\nax3d = fig.add_subplot(122, projection='3d')\nraw.plot_sensors(ch_type='eeg', axes=ax2d)\nraw.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\nax3d.view_init(azim=70, elev=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nReading sensor digitization files\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt's probably evident from the 2D topomap above that there is some\nirregularity in the EEG sensor positions in the `sample dataset\n<sample-dataset>` \u2014 this is because the sensor positions in that dataset are\ndigitizations of the sensor positions on an actual subject's head. Sensor\ndigitizations are read with :func:`mne.channels.read_dig_montage` and added\nto :class:`~mne.io.Raw` objects with the :meth:`~mne.io.Raw.set_montage`\nmethod; in the sample data this was done prior to saving the\n:class:`~mne.io.Raw` object to disk, so the sensor positions are already\nincorporated into the ``info`` attribute of the :class:`~mne.io.Raw` object.\nSee the documentation of :func:`~mne.channels.read_dig_montage` and\n:meth:`~mne.io.Raw.set_montage` for further details. Once loaded,\n:class:`~mne.channels.DigMontage` objects work similarly to\n:class:`~mne.channels.Montage` objects (e.g, they have similar\n:meth:`~mne.channels.DigMontage.plot` and\n:meth:`~mne.channels.DigMontage.save` methods).\n\n.. TODO sample data doesn't have separate .hsp or .elp files, so can't demo\n   this functionality\n\n\nRendering sensor position with mayavi\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIt is also possible to render an image of a MEG sensor helmet in 3D, using\nmayavi instead of matplotlib, by calling the :func:`mne.viz.plot_alignment`\nfunction:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(raw.info, trans=None, dig=False, eeg=False,\n                             surfaces=[], meg=['helmet', 'sensors'],\n                             coord_frame='meg')\nmne.viz.set_3d_view(fig, azimuth=50, elevation=90, distance=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":func:`~mne.viz.plot_alignment` requires an :class:`~mne.Info` object, and\ncan also render MRI surfaces of the scalp, skull, and brain (by passing\nkeywords like ``'head'``, ``'outer_skull'``, or ``'brain'`` to the\n``surfaces`` parameter) making it useful for `assessing coordinate frame\ntransformations <plot_source_alignment>`. For examples of various uses of\n:func:`~mne.viz.plot_alignment`, see\n:doc:`../../auto_examples/visualization/plot_montage`,\n:doc:`../../auto_examples/visualization/plot_eeg_on_scalp`, and\n:doc:`../../auto_examples/visualization/plot_meg_sensors`.\n\n.. LINKS\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}